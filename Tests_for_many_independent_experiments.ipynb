{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOEvcFTQ4Y9G8REW3fth3/r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lawgorithm/large_scale_inference/blob/main/Tests_for_many_independent_experiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "# from scipy.stats import t\n",
        "# from scipy.stats import norm\n",
        "import statsmodels.formula.api as smf\n"
      ],
      "metadata": {
        "id": "N-HWH26ygrB3"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simulate observed data"
      ],
      "metadata": {
        "id": "vD3jqcn-jfBB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_normal_normal_samples(n_samples, mu, tau2):\n",
        "    \"\"\"\n",
        "    Generates samples from a Normal-Normal hierarchical model.  V is simulated\n",
        "    sampled from an Inverse Gamma distribution.\n",
        "\n",
        "    Args:\n",
        "        n_samples (int): The number of samples to generate.\n",
        "        mu (float): The prior mean of theta.\n",
        "        tau2 (float): The prior variance of theta.\n",
        "\n",
        "    Returns:\n",
        "        tuple: A tuple containing:\n",
        "            - theta (array-like): The generated theta values.\n",
        "            - y (array-like): The generated y values.\n",
        "            - V (array-like): The generated V values (observation variances).\n",
        "    \"\"\"\n",
        "\n",
        "    # Generate theta values from the prior distribution\n",
        "    theta = np.random.normal(mu, np.sqrt(tau2), n_samples)\n",
        "\n",
        "    # Simulate V values from an Inverse Gamma distribution (example prior)\n",
        "    alpha = 5  # Shape parameter for the Inverse Gamma\n",
        "    beta = 5   # Scale parameter for the Inverse Gamma\n",
        "    V = 1.0 / np.random.gamma(alpha, 1.0 / beta, n_samples)\n",
        "\n",
        "    # Generate y values from the conditional distribution (vectorized)\n",
        "    y = np.random.normal(theta, np.sqrt(V))\n",
        "\n",
        "    return theta, y, V"
      ],
      "metadata": {
        "id": "14-I_GrHiswj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "n_samples = 100\n",
        "mu = 0\n",
        "tau2 = 2\n",
        "\n",
        "theta, y, V = generate_normal_normal_samples(n_samples, mu, tau2)\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    \"true_mean\": theta,\n",
        "    \"y\": y,\n",
        "    \"true_SD\": V**0.5\n",
        "})\n",
        "df['experiment'] = range(len(df['true_mean']))\n",
        "df['experiment']= df['experiment'].astype(str)\n",
        "\n",
        "NUM_BUCKETS = 19\n",
        "for index, row in df.iterrows():\n",
        "  samples = np.random.normal(\n",
        "    loc=row['true_mean'],\n",
        "    scale=row['true_SD'],\n",
        "    size=19\n",
        "  )\n",
        "  df_tmp = pd.DataFrame({\n",
        "    \"y\": samples,\n",
        "  })\n",
        "  df_tmp['true_mean'] = row['true_mean']\n",
        "  df_tmp['true_SD'] = row['true_SD']\n",
        "  df_tmp['experiment'] = row['experiment']\n",
        "  df = pd.concat([df, df_tmp], ignore_index=True)\n",
        "\n",
        "df = df.sort_values(by=['experiment']).reset_index(drop=True)\n",
        "df\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "2yTbl64H6iCq",
        "outputId": "395cef28-d9a1-4f52-e045-b06be1187b1f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      true_mean         y   true_SD experiment\n",
              "0     -2.983310 -2.237498  0.885909          0\n",
              "1     -2.983310 -3.416547  0.885909          0\n",
              "2     -2.983310 -2.142861  0.885909          0\n",
              "3     -2.983310 -2.366834  0.885909          0\n",
              "4     -2.983310 -3.469896  0.885909          0\n",
              "...         ...       ...       ...        ...\n",
              "1995  -0.480427  0.764505  1.401126         99\n",
              "1996  -0.480427 -2.011671  1.401126         99\n",
              "1997  -0.480427  0.359882  1.401126         99\n",
              "1998  -0.480427 -1.188932  1.401126         99\n",
              "1999  -0.480427 -1.608820  1.401126         99\n",
              "\n",
              "[2000 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-255e77ed-67fe-45ab-91a1-1c0684f446b3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>true_mean</th>\n",
              "      <th>y</th>\n",
              "      <th>true_SD</th>\n",
              "      <th>experiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-2.983310</td>\n",
              "      <td>-2.237498</td>\n",
              "      <td>0.885909</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-2.983310</td>\n",
              "      <td>-3.416547</td>\n",
              "      <td>0.885909</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-2.983310</td>\n",
              "      <td>-2.142861</td>\n",
              "      <td>0.885909</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-2.983310</td>\n",
              "      <td>-2.366834</td>\n",
              "      <td>0.885909</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-2.983310</td>\n",
              "      <td>-3.469896</td>\n",
              "      <td>0.885909</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1995</th>\n",
              "      <td>-0.480427</td>\n",
              "      <td>0.764505</td>\n",
              "      <td>1.401126</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1996</th>\n",
              "      <td>-0.480427</td>\n",
              "      <td>-2.011671</td>\n",
              "      <td>1.401126</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1997</th>\n",
              "      <td>-0.480427</td>\n",
              "      <td>0.359882</td>\n",
              "      <td>1.401126</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>-0.480427</td>\n",
              "      <td>-1.188932</td>\n",
              "      <td>1.401126</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1999</th>\n",
              "      <td>-0.480427</td>\n",
              "      <td>-1.608820</td>\n",
              "      <td>1.401126</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2000 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-255e77ed-67fe-45ab-91a1-1c0684f446b3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-255e77ed-67fe-45ab-91a1-1c0684f446b3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-255e77ed-67fe-45ab-91a1-1c0684f446b3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c7e278e2-ca99-4692-80d5-734be2c1a161\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c7e278e2-ca99-4692-80d5-734be2c1a161')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c7e278e2-ca99-4692-80d5-734be2c1a161 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_1512de57-a8ae-4e7b-8b34-5a9d9ad6301f\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1512de57-a8ae-4e7b-8b34-5a9d9ad6301f button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 2000,\n  \"fields\": [\n    {\n      \"column\": \"true_mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.4205599965381315,\n        \"min\": -3.9574024803762553,\n        \"max\": 2.609557944976831,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          -2.462587200235975,\n          0.02940060486535952,\n          0.9151237863153048\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.8344335352986991,\n        \"min\": -6.418261324680914,\n        \"max\": 5.80130953071878,\n        \"num_unique_values\": 2000,\n        \"samples\": [\n          1.1835988532320283,\n          3.179778172818178,\n          -3.687902957758194\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"true_SD\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2933402140148703,\n        \"min\": 0.6437385967710598,\n        \"max\": 2.28724471820574,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          1.127019371566596,\n          1.227441863752431,\n          1.128612873493441\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"experiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"84\",\n          \"57\",\n          \"72\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df_agg = df.groupby(['true_mean', 'true_SD'], as_index=False).agg(\n",
        "#     y_bar = ('y', 'mean'),\n",
        "#     SE = ('y', 'std'))\n",
        "df_agg = df.groupby(['experiment'], as_index=False).agg(\n",
        "    y_bar = ('y', 'mean'),\n",
        "    SE = ('y', 'std')).sort_values(by=['experiment'])\n",
        "df_agg['DoF'] = 19\n",
        "df_agg['t_stat'] = df_agg['y_bar'] / df_agg['SE']\n",
        "df_agg.head()"
      ],
      "metadata": {
        "id": "hlti6OxAjZSY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "1242247d-63e4-434a-ef1e-a33fab16a426"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  experiment     y_bar        SE  DoF    t_stat\n",
              "0          0 -3.166691  0.978545   19 -3.236121\n",
              "1          1  0.339858  0.776514   19  0.437672\n",
              "2         10  0.984978  3.191718   19  0.308604\n",
              "3         11 -1.750995  0.773178   19 -2.264673\n",
              "4         12 -1.601219  1.051505   19 -1.522788"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ddcaccaf-fa05-4ea0-aca1-2b3194fa1df9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>experiment</th>\n",
              "      <th>y_bar</th>\n",
              "      <th>SE</th>\n",
              "      <th>DoF</th>\n",
              "      <th>t_stat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>-3.166691</td>\n",
              "      <td>0.978545</td>\n",
              "      <td>19</td>\n",
              "      <td>-3.236121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.339858</td>\n",
              "      <td>0.776514</td>\n",
              "      <td>19</td>\n",
              "      <td>0.437672</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10</td>\n",
              "      <td>0.984978</td>\n",
              "      <td>3.191718</td>\n",
              "      <td>19</td>\n",
              "      <td>0.308604</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11</td>\n",
              "      <td>-1.750995</td>\n",
              "      <td>0.773178</td>\n",
              "      <td>19</td>\n",
              "      <td>-2.264673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12</td>\n",
              "      <td>-1.601219</td>\n",
              "      <td>1.051505</td>\n",
              "      <td>19</td>\n",
              "      <td>-1.522788</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ddcaccaf-fa05-4ea0-aca1-2b3194fa1df9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ddcaccaf-fa05-4ea0-aca1-2b3194fa1df9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ddcaccaf-fa05-4ea0-aca1-2b3194fa1df9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-576b0786-16ef-4767-964e-acb352629f0c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-576b0786-16ef-4767-964e-acb352629f0c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-576b0786-16ef-4767-964e-acb352629f0c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_agg",
              "summary": "{\n  \"name\": \"df_agg\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"experiment\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"84\",\n          \"57\",\n          \"72\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_bar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.463844749188017,\n        \"min\": -3.6845039953260574,\n        \"max\": 3.045839140477924,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          -2.554743634855565,\n          0.30356554922998646,\n          1.05404646436312\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.37537023818948434,\n        \"min\": 0.5702796806686159,\n        \"max\": 3.1917182283362386,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          1.2516067658236734,\n          1.332132295345505,\n          1.2209714800997151\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DoF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 19,\n        \"max\": 19,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          19\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"t_stat\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.494222388635669,\n        \"min\": -4.013530747282685,\n        \"max\": 3.6744779537998156,\n        \"num_unique_values\": 100,\n        \"samples\": [\n          -2.0411711606355105\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methods that use aggregated summaries like t-stats or p-values"
      ],
      "metadata": {
        "id": "KxRD8pYOF103"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fisher's Method\n",
        "\n",
        "**Overview**\n",
        "\n",
        "Convert each t-statistic to a p-value (using the appropriate degrees of freedom) and then compute:\n",
        "\n",
        "$$ X = -2 \\sum_{i=1}^k \\log{p_i} $$\n",
        "\n",
        "Under the global null, follows a chi-square distribution with\n",
        "2 * k degrees of freedom. This approach is powerful when the tests are independent\n",
        "\n",
        "**Global Null (TODO)**\n",
        "\n",
        "wikipedia say's fisher's method is \"is used to combine the results from several independence tests bearing upon the same overall hypothesis (H0)\" -- that doesn't seem to be the case here. I am not replicating the same test over and over (in which case they would have the same null) -- rather, I am running many different independent tests. Is that a problem?\n",
        "\n",
        "Fisher's method is designed to combine p‑values from independent tests that all address the same overall null hypothesis. In your case, even though you're running different tests (one in each zip code), if each test's null hypothesis is “no effect in that zip code” then collectively they address the global null hypothesis “no zip code has an effect.” That means you're effectively testing the same hypothesis in different independent settings.\n",
        "\n",
        "So, even though the tests come from different locations, as long as:\n",
        "\n",
        "Each test is carried out correctly (yielding valid p‑values under its own null), and\n",
        "The tests are independent (or approximately so),\n",
        "Fisher's method (or other p‑value combination methods) is applicable. The key is that all tests are assessing the same overall hypothesis (zero effect everywhere), even if the tests themselves differ in power or sample size.\n",
        "\n",
        "If the tests were addressing fundamentally different null hypotheses, then combining them with Fisher's method wouldn’t be appropriate. But here, since the underlying null is conceptually the same, using Fisher's method is valid.\n",
        "\n",
        "**References**\n",
        "\n",
        "* [Asymptotic Optimality of Fisher's Method of Combining Independent Tests](https://www.tandfonline.com/doi/abs/10.1080/01621459.1971.10482347)\n",
        "* [Powerful p-value combination methods to detect incomplete association](https://www.nature.com/articles/s41598-021-86465-y)\n",
        "\n",
        "**Independence Assumption**\n",
        "\n",
        "Fisher's method combines p-values by assuming that they are independent. In genetic studies—and other high-dimensional applications—the tests are often correlated. For many parallel, independent experiments, it should be fine.\n",
        "\n",
        "**Limitations**\n",
        "\n",
        "* While Fisher's method is perfectly valid under independence, it can be overly influenced by a few very small p-values. Fisher's method sums the logarithms of p-values, so a few very small p-values can dominate the test statistic."
      ],
      "metadata": {
        "id": "sDZ1tGxQioGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fisher_combined_pvalue(t_stats, dof):\n",
        "    \"\"\"\n",
        "    Combine p-values from independent t-tests using Fisher's method.\n",
        "\n",
        "    Parameters:\n",
        "      t_stats : array_like\n",
        "          Array of t-statistics from individual experiments.\n",
        "      dof : int or array_like\n",
        "          Degrees of freedom for each t-statistic (can be scalar if same for all).\n",
        "\n",
        "    Returns:\n",
        "      X : float\n",
        "          The Fisher combined test statistic.\n",
        "      p_value : float\n",
        "          Combined p-value under the global null.\n",
        "    \"\"\"\n",
        "    # Convert each t-statistic to a two-sided p-value.\n",
        "    t_stats = np.asarray(t_stats)\n",
        "    if np.isscalar(dof):\n",
        "        dof = np.full(t_stats.shape, dof)\n",
        "    p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), dof))\n",
        "\n",
        "    # Fisher's method statistic\n",
        "    X = -2 * np.sum(np.log(p_values))\n",
        "\n",
        "    # Under the null, X ~ chi2 with 2*k degrees of freedom, where k = number of tests.\n",
        "    k = len(t_stats)\n",
        "    p_value = 1 - stats.chi2.cdf(X, 2*k)\n",
        "    return X, p_value"
      ],
      "metadata": {
        "id": "_Ngup2GTSmvL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check behavior for null effects\n",
        "\n",
        "np.random.seed(42)\n",
        "n_experiments = 1000\n",
        "# suppose each experiment has 20 observations\n",
        "dof = 19\n",
        "\n",
        "# Generate 1000 t-statistics under the global null (no true effect).\n",
        "# Under H0, t-statistics follow a t-distribution.\n",
        "t_stats_null = np.random.standard_t(dof, size=n_experiments)\n",
        "\n",
        "X, combined_p = fisher_combined_pvalue(t_stats_null, dof)\n",
        "print(\"Fisher combined statistic:\", X)\n",
        "print(\"Combined p-value:\", combined_p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u46kZFT2bXv4",
        "outputId": "256ddd68-7bd8-439b-f6a9-dd10bb733e31"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fisher combined statistic: 1983.4123943800714\n",
            "Combined p-value: 0.5996546079628109\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check behavior for non-null simulated data\n",
        "\n",
        "X, combined_p = fisher_combined_pvalue(\n",
        "    t_stats=df_agg['t_stat'],\n",
        "    dof=df_agg['DoF'])\n",
        "print(\"Fisher combined statistic:\", X)\n",
        "print(\"Combined p-value:\", combined_p)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfcoC2QRcIDo",
        "outputId": "2c573c32-340b-422d-9a64-e2e79685f174"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fisher combined statistic: 321.44768430729\n",
            "Combined p-value: 1.0858032739591295e-07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stouffer's Method\n",
        "\n",
        "Stouffer’s Method (Weighted Z‐Test):\n",
        "First, each independent t-statistic to an equivilent p-value. Then, use the normal density to convert each p-value to a z-score. Then combine them by summing (possibly with weights) and standardizing. Because the tests are independent, the sum (appropriately normalized) will be approximately standard normal under the global null. This method is less dominated by a few extremely small p‑values compared to Fisher’s method and is quite natural when many tests are weak.\n",
        "\n",
        "Here you convert each test’s p‑value to a z‑score (or directly convert the t‑statistic if the degrees of freedom are similar across tests), then combine them:\n",
        "\n",
        "$$Z_{\\text{combined}} = \\frac{\\sum_{i=1}^p N_i}{\\sqrt{p}}$$\n",
        "\n",
        "where each $Z_i$ is the z-score corresponding to the i-th test. Under the global null,\n",
        "\n",
        "$$Z_{\\text{combined}} \\sim N(0,1) $$\n",
        "\n",
        "This method can be more robust when the signals are weak and spread out, and you can also apply weights if some tests are more precise than others."
      ],
      "metadata": {
        "id": "6YSeFKxml2LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def stouffer_combined_pvalue(t_stats, dof):\n",
        "    \"\"\"\n",
        "    Combine p-values from independent t-tests using Stouffer's method (Z-score combination).\n",
        "\n",
        "    Parameters:\n",
        "      t_stats : array_like\n",
        "          Array of t-statistics from individual experiments.\n",
        "      df : int or array_like\n",
        "          Degrees of freedom for each t-statistic (assumed identical here for simplicity).\n",
        "\n",
        "    Returns:\n",
        "      Z_combined : float\n",
        "          The combined Z-score.\n",
        "      p_value : float\n",
        "          Combined p-value under the global null.\n",
        "    \"\"\"\n",
        "    t_stats = np.asarray(t_stats)\n",
        "    if np.isscalar(dof):\n",
        "        dof = np.full(t_stats.shape, dof)\n",
        "    # Convert to two-sided p-values and then to Z-scores\n",
        "    p_values = 2 * (1 - stats.t.cdf(np.abs(t_stats), dof))\n",
        "    # For a two-sided test, convert p-values to Z-scores:\n",
        "    Z_scores = stats.norm.ppf(1 - p_values/2)\n",
        "    # Restore the sign of t-statistics\n",
        "    Z_scores = np.sign(t_stats) * Z_scores\n",
        "    # Combine Z-scores; if tests are equally weighted:\n",
        "    Z_combined = np.sum(Z_scores) / np.sqrt(len(Z_scores))\n",
        "    combined_p = 2 * (1 - stats.norm.cdf(np.abs(Z_combined)))\n",
        "    return Z_combined, combined_p"
      ],
      "metadata": {
        "id": "4XzKA_cMl4Ap"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check behavior for null effects\n",
        "\n",
        "Z_combined, combined_p_stouffer = stouffer_combined_pvalue(\n",
        "    t_stats=t_stats_null,\n",
        "    dof=dof)\n",
        "print(\"Stouffer combined Z:\", Z_combined)\n",
        "print(\"Combined p-value:\", combined_p_stouffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIHI_ePYc8fD",
        "outputId": "ee6ff69a-1203-46ad-b4da-6674edae3b3a"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stouffer combined Z: -1.5182621845214257\n",
            "Combined p-value: 0.12894831667914253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check behavior for non-null simulated data\n",
        "\n",
        "Z_combined, combined_p_stouffer = stouffer_combined_pvalue(\n",
        "    t_stats=df_agg['t_stat'],\n",
        "    dof=df_agg['DoF']\n",
        ")\n",
        "print(\"Stouffer combined Z:\", Z_combined)\n",
        "print(\"Combined p-value:\", combined_p_stouffer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-_aH1zPdTi0",
        "outputId": "336d6764-3314-4f0a-a367-2dcf6b48b5bf"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stouffer combined Z: -2.738527779072329\n",
            "Combined p-value: 0.006171494642797537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methods that use the raw data"
      ],
      "metadata": {
        "id": "d8Hs0irVF_CZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why use the raw data rather than combine t-stats, z-scores or p-values?\n",
        "\n",
        "Imagine the following thought experiment: suppose you replicate the same experiment twice. Is it more powerful to compute a p-value for each and then use fisher's method (or a similar method that aggregates p-values or t-statistics)? Or should you combine all the data and do a sinlge test?\n",
        "\n",
        "When the same experiment is replicated under identical conditions, combining all the data into a single test is usually more powerful than analyzing each replication separately and then combining the p-values (e.g., via Fisher's method).\n",
        "\n",
        "Combining the raw data yields a larger overall sample size, which improves the precision of estimates and increases the test's power. When you run separate tests and then combine p-values, you lose some information about the effect sizes and their variability. A single test that pools the data uses all available degrees of freedom, whereas separate tests have fewer degrees of freedom each. Pooling data also typically results in a more reliable estimate of the common variance.\n",
        "\n",
        "Methods like Fisher's method are designed for situations where you might not have access to the raw data (for example, if studies are published separately) or if the studies differ in design. When the experiments are identical, a joint analysis is both simpler and more statistically efficient."
      ],
      "metadata": {
        "id": "gNL9sZrXNiB1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ANOVA\n"
      ],
      "metadata": {
        "id": "0WdW_fIHywRZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case you do have individual-level observations for each experiment, you can treat “experiment_id” as a categorical factor in a regression model or ANOVA. For example, you might fit a model like\n",
        "\n",
        "$$y_{ij} = \\mu + \\alpha_j + \\epsilon_{ij}$$\n",
        "\n",
        "where $\\alpha_j$ represents the deviation for each experiment.\n",
        "\n",
        "Here the global null hypothesis is\n",
        "\n",
        "$$ H_0: \\alpha_1 = ... = \\alpha_j = 0 $$\n",
        "\n",
        "meaning all experiments have the same mean. This is a standard ANOVA problem, and you can test it with an F-test.\n",
        "\n",
        "Below, we do this by building a weighted least squares regression (using weighted least squares to handle heterskedasticity of the error terms in the model above).\n",
        "\n",
        "We can then either:\n",
        "*   Use a likelihood ratio test to test the significance of the categorical variable (equivilent to testing whether $\\alpha_1 = ... = \\alpha_j = 0)$ via LRT\n",
        "*   Directly use an ANOVA F-test\n",
        "\n",
        "**References**\n",
        "\n",
        "* [ANOVA F-test](https://en.wikipedia.org/wiki/F-test#One-way_analysis_of_variance)\n",
        "* ANOVA in Casella and Berger"
      ],
      "metadata": {
        "id": "vGlHnH7O0C9v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# In this approach, weights are inversely proportional to each experiment's\n",
        "# sampling variance.\n",
        "\n",
        "df_anova = df.merge(\n",
        "    df_agg[['experiment', 'SE']],\n",
        "    how='left',\n",
        "    on=['experiment']).copy()\n",
        "df_anova = df_anova[['experiment', 'y', 'SE']]\n",
        "df_anova['weights'] = 1 / df_anova['SE']**2\n",
        "\n",
        "# Fit full WLS model\n",
        "wls_full_model = smf.wls(\n",
        "    \"y ~ C(experiment)\",\n",
        "    data=df_anova,\n",
        "    weights=df_anova['weights']\n",
        "    ).fit()\n",
        "\n",
        "# Fit the reduced WLS model (without experiment)\n",
        "wls_reduced_model = smf.wls(\n",
        "    \"y ~ 1\",  # Intercept-only model\n",
        "    data=df_anova,\n",
        "    weights=df_anova['weights']\n",
        ").fit()\n",
        "\n",
        "# Note: the F-statistic printed here is the same as the F-stats printed below\n",
        "print(wls_full_model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJkU4fEzyx4_",
        "outputId": "d7de3b18-b769-4414-eb2d-4df8dfe26879"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                            WLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   R-squared:                       0.702\n",
            "Model:                            WLS   Adj. R-squared:                  0.687\n",
            "Method:                 Least Squares   F-statistic:                     45.24\n",
            "Date:                Sun, 23 Feb 2025   Prob (F-statistic):               0.00\n",
            "Time:                        20:28:15   Log-Likelihood:                -2846.6\n",
            "No. Observations:                2000   AIC:                             5893.\n",
            "Df Residuals:                    1900   BIC:                             6453.\n",
            "Df Model:                          99                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "=======================================================================================\n",
            "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
            "---------------------------------------------------------------------------------------\n",
            "Intercept              -3.1667      0.219    -14.472      0.000      -3.596      -2.738\n",
            "C(experiment)[T.1]      3.5065      0.279     12.553      0.000       2.959       4.054\n",
            "C(experiment)[T.10]     4.1517      0.746      5.562      0.000       2.688       5.616\n",
            "C(experiment)[T.11]     1.4157      0.279      5.077      0.000       0.869       1.963\n",
            "C(experiment)[T.12]     1.5655      0.321      4.874      0.000       0.936       2.195\n",
            "C(experiment)[T.13]     2.7832      0.394      7.073      0.000       2.012       3.555\n",
            "C(experiment)[T.14]     3.7056      0.450      8.227      0.000       2.822       4.589\n",
            "C(experiment)[T.15]     2.7626      0.407      6.780      0.000       1.964       3.562\n",
            "C(experiment)[T.16]     3.6843      0.336     10.976      0.000       3.026       4.343\n",
            "C(experiment)[T.17]     0.0485      0.304      0.160      0.873      -0.548       0.645\n",
            "C(experiment)[T.18]     2.9622      0.281     10.529      0.000       2.410       3.514\n",
            "C(experiment)[T.19]     2.0230      0.275      7.346      0.000       1.483       2.563\n",
            "C(experiment)[T.2]      2.3302      0.285      8.176      0.000       1.771       2.889\n",
            "C(experiment)[T.20]     3.1752      0.271     11.723      0.000       2.644       3.706\n",
            "C(experiment)[T.21]     2.5954      0.288      9.018      0.000       2.031       3.160\n",
            "C(experiment)[T.22]     5.0432      0.272     18.529      0.000       4.509       5.577\n",
            "C(experiment)[T.23]     3.3244      0.263     12.641      0.000       2.809       3.840\n",
            "C(experiment)[T.24]     2.7391      0.355      7.714      0.000       2.043       3.435\n",
            "C(experiment)[T.25]     0.2970      0.359      0.827      0.408      -0.408       1.002\n",
            "C(experiment)[T.26]     5.1355      0.290     17.718      0.000       4.567       5.704\n",
            "C(experiment)[T.27]     0.7787      0.348      2.240      0.025       0.097       1.460\n",
            "C(experiment)[T.28]     5.7164      0.292     19.586      0.000       5.144       6.289\n",
            "C(experiment)[T.29]     1.0494      0.281      3.731      0.000       0.498       1.601\n",
            "C(experiment)[T.3]      0.2552      0.298      0.857      0.392      -0.329       0.839\n",
            "C(experiment)[T.30]     1.8164      0.390      4.663      0.000       1.052       2.580\n",
            "C(experiment)[T.31]     3.5840      0.330     10.856      0.000       2.937       4.231\n",
            "C(experiment)[T.32]     2.3970      0.279      8.599      0.000       1.850       2.944\n",
            "C(experiment)[T.33]     3.5486      0.315     11.266      0.000       2.931       4.166\n",
            "C(experiment)[T.34]     4.4890      0.294     15.268      0.000       3.912       5.066\n",
            "C(experiment)[T.35]     0.9865      0.407      2.426      0.015       0.189       1.784\n",
            "C(experiment)[T.36]     3.1457      0.400      7.856      0.000       2.360       3.931\n",
            "C(experiment)[T.37]     2.6107      0.254     10.296      0.000       2.113       3.108\n",
            "C(experiment)[T.38]     1.2863      0.281      4.582      0.000       0.736       1.837\n",
            "C(experiment)[T.39]     1.8045      0.452      3.994      0.000       0.918       2.691\n",
            "C(experiment)[T.4]      1.1603      0.311      3.732      0.000       0.550       1.770\n",
            "C(experiment)[T.40]     3.2546      0.446      7.303      0.000       2.381       4.129\n",
            "C(experiment)[T.41]     2.8268      0.289      9.776      0.000       2.260       3.394\n",
            "C(experiment)[T.42]     2.9970      0.413      7.254      0.000       2.187       3.807\n",
            "C(experiment)[T.43]     2.2883      0.374      6.117      0.000       1.555       3.022\n",
            "C(experiment)[T.44]     3.4220      0.301     11.372      0.000       2.832       4.012\n",
            "C(experiment)[T.45]     3.3550      0.300     11.198      0.000       2.767       3.943\n",
            "C(experiment)[T.46]     4.6173      0.311     14.840      0.000       4.007       5.228\n",
            "C(experiment)[T.47]     2.6748      0.269      9.954      0.000       2.148       3.202\n",
            "C(experiment)[T.48]     5.0076      0.308     16.276      0.000       4.404       5.611\n",
            "C(experiment)[T.49]     4.7342      0.288     16.416      0.000       4.169       5.300\n",
            "C(experiment)[T.5]      1.7750      0.382      4.647      0.000       1.026       2.524\n",
            "C(experiment)[T.50]     4.6812      0.285     16.415      0.000       4.122       5.240\n",
            "C(experiment)[T.51]     1.5172      0.291      5.220      0.000       0.947       2.087\n",
            "C(experiment)[T.52]     2.0407      0.341      5.989      0.000       1.372       2.709\n",
            "C(experiment)[T.53]     1.4278      0.297      4.814      0.000       0.846       2.009\n",
            "C(experiment)[T.54]     5.4002      0.272     19.889      0.000       4.868       5.933\n",
            "C(experiment)[T.55]     2.8792      0.379      7.596      0.000       2.136       3.623\n",
            "C(experiment)[T.56]     0.9833      0.337      2.919      0.004       0.323       1.644\n",
            "C(experiment)[T.57]     3.4703      0.370      9.389      0.000       2.745       4.195\n",
            "C(experiment)[T.58]     1.9794      0.257      7.715      0.000       1.476       2.483\n",
            "C(experiment)[T.59]     4.0484      0.313     12.952      0.000       3.435       4.661\n",
            "C(experiment)[T.6]      1.2570      0.347      3.618      0.000       0.576       1.938\n",
            "C(experiment)[T.60]    -0.5178      0.300     -1.726      0.085      -1.106       0.071\n",
            "C(experiment)[T.61]     3.7897      0.342     11.066      0.000       3.118       4.461\n",
            "C(experiment)[T.62]     2.8878      0.295      9.802      0.000       2.310       3.466\n",
            "C(experiment)[T.63]     3.3227      0.350      9.490      0.000       2.636       4.009\n",
            "C(experiment)[T.64]     5.1323      0.297     17.275      0.000       4.550       5.715\n",
            "C(experiment)[T.65]     2.7233      0.293      9.309      0.000       2.150       3.297\n",
            "C(experiment)[T.66]     5.5119      0.261     21.099      0.000       5.000       6.024\n",
            "C(experiment)[T.67]     3.0272      0.365      8.299      0.000       2.312       3.743\n",
            "C(experiment)[T.68]     1.2029      0.292      4.115      0.000       0.630       1.776\n",
            "C(experiment)[T.69]    -0.3358      0.351     -0.957      0.339      -1.024       0.353\n",
            "C(experiment)[T.7]      3.8042      0.339     11.222      0.000       3.139       4.469\n",
            "C(experiment)[T.70]     0.2038      0.489      0.417      0.677      -0.754       1.162\n",
            "C(experiment)[T.71]     3.6051      0.334     10.784      0.000       2.950       4.261\n",
            "C(experiment)[T.72]     4.2207      0.350     12.063      0.000       3.535       4.907\n",
            "C(experiment)[T.73]     3.9688      0.271     14.633      0.000       3.437       4.501\n",
            "C(experiment)[T.74]     1.3153      0.298      4.409      0.000       0.730       1.900\n",
            "C(experiment)[T.75]     3.4129      0.298     11.457      0.000       2.829       3.997\n",
            "C(experiment)[T.76]     3.0622      0.326      9.384      0.000       2.422       3.702\n",
            "C(experiment)[T.77]     4.0482      0.287     14.102      0.000       3.485       4.611\n",
            "C(experiment)[T.78]     2.9724      0.327      9.092      0.000       2.331       3.614\n",
            "C(experiment)[T.79]     2.4984      0.284      8.794      0.000       1.941       3.056\n",
            "C(experiment)[T.8]      2.1431      0.307      6.989      0.000       1.542       2.744\n",
            "C(experiment)[T.80]     4.1991      0.285     14.742      0.000       3.640       4.758\n",
            "C(experiment)[T.81]     0.1289      0.349      0.370      0.712      -0.555       0.813\n",
            "C(experiment)[T.82]     3.9677      0.347     11.432      0.000       3.287       4.648\n",
            "C(experiment)[T.83]     1.7895      0.313      5.716      0.000       1.175       2.404\n",
            "C(experiment)[T.84]     0.6119      0.355      1.723      0.085      -0.085       1.309\n",
            "C(experiment)[T.85]     3.8790      0.337     11.509      0.000       3.218       4.540\n",
            "C(experiment)[T.86]     2.3819      0.294      8.100      0.000       1.805       2.959\n",
            "C(experiment)[T.87]     2.6175      0.293      8.943      0.000       2.043       3.191\n",
            "C(experiment)[T.88]     4.4666      0.285     15.692      0.000       3.908       5.025\n",
            "C(experiment)[T.89]     3.9337      0.319     12.327      0.000       3.308       4.560\n",
            "C(experiment)[T.9]      4.4314      0.319     13.874      0.000       3.805       5.058\n",
            "C(experiment)[T.90]     6.2125      0.488     12.736      0.000       5.256       7.169\n",
            "C(experiment)[T.91]     2.5385      0.304      8.339      0.000       1.942       3.136\n",
            "C(experiment)[T.92]     3.2584      0.291     11.196      0.000       2.688       3.829\n",
            "C(experiment)[T.93]     3.6891      0.253     14.567      0.000       3.192       4.186\n",
            "C(experiment)[T.94]     1.7493      0.381      4.597      0.000       1.003       2.496\n",
            "C(experiment)[T.95]     2.6199      0.330      7.938      0.000       1.973       3.267\n",
            "C(experiment)[T.96]     3.1034      0.331      9.381      0.000       2.455       3.752\n",
            "C(experiment)[T.97]     3.2022      0.300     10.674      0.000       2.614       3.791\n",
            "C(experiment)[T.98]     5.0055      0.485     10.323      0.000       4.055       5.956\n",
            "C(experiment)[T.99]     2.2325      0.398      5.609      0.000       1.452       3.013\n",
            "==============================================================================\n",
            "Omnibus:                       13.749   Durbin-Watson:                   2.080\n",
            "Prob(Omnibus):                  0.001   Jarque-Bera (JB):                9.698\n",
            "Skew:                           0.001   Prob(JB):                      0.00783\n",
            "Kurtosis:                       2.659   Cond. No.                         104.\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Likelihood ratio test testing significance of categorical variable\n",
        "lr_stat = 2 * (wls_full_model.llf - wls_reduced_model.llf)\n",
        "df_diff = wls_full_model.df_model - wls_reduced_model.df_model\n",
        "p_value = 1 - stats.chi2.cdf(lr_stat, df_diff) # check whether this is correct test for LRT\n",
        "print(f\"LR Statistic: {lr_stat}\")\n",
        "print(f\"p-value: {p_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFsPmAymyy2y",
        "outputId": "361b00d4-e125-4e5a-9e1a-e62df1a4e67c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LR Statistic: 2422.268386652835\n",
            "p-value: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Direct F-test testing significance of categorical variable\n",
        "f_test = wls_full_model.compare_f_test(wls_reduced_model)\n",
        "print(f\"F statistic: {f_test[0]}, p-value: {f_test[1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhhULOjaZ9on",
        "outputId": "c05853c9-f552-4c61-ad16-2b3751702764"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F statistic: 45.24092514582824, p-value: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Recreation of F-test\n",
        "\n",
        "# Calculate WSS\n",
        "wss_full = wls_full_model.ssr\n",
        "wss_reduced = wls_reduced_model.ssr\n",
        "\n",
        "# Degrees of freedom\n",
        "df_full = wls_full_model.df_resid\n",
        "df_reduced = wls_reduced_model.df_resid\n",
        "\n",
        "# \"F-like\" statistic\n",
        "f_statistic = ((wss_reduced - wss_full) / (df_reduced - df_full)) / (wss_full / df_full)\n",
        "\n",
        "# P-value (using F-distribution)\n",
        "p_value = 1 - stats.f.cdf(f_statistic, df_reduced - df_full, df_full) # Need scipy for this\n",
        "\n",
        "print(f\"WSS Full Model: {wss_full}\")\n",
        "print(f\"WSS Reduced Model: {wss_reduced}\")\n",
        "print(f\"F-statistic: {f_statistic}\")\n",
        "print(f\"P-value: {p_value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDoQXBpasLYH",
        "outputId": "8519a374-a365-4f39-e6b9-01fadfc0aebe"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WSS Full Model: 1900.0\n",
            "WSS Reduced Model: 6378.851589436996\n",
            "F-statistic: 45.24092514582824\n",
            "P-value: 1.1102230246251565e-16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "assert False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 135
        },
        "id": "1_rFrOpmdaub",
        "outputId": "a6df1142-bf27-452d-c899-f443ed60457c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-a871fdc9ebee>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32massert\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mixed Effects (frequentist)\n",
        "\n",
        "Interesting. Suppose instead i replicate the same experiment twice. Is it more powerful to compute a pvalur for each and then use fisher’s method? Or combine all the data and do a sinlge test?\n",
        "\n",
        "When the same experiment is replicated under identical conditions, combining all the data into a single test is usually more powerful than analyzing each replication separately and then combining the p‑values (e.g., via Fisher’s method). Here’s why:\n",
        "\n",
        "Efficiency and Information Use:\n",
        "Combining the raw data yields a larger overall sample size, which improves the precision of estimates and increases the test’s power. When you run separate tests and then combine p‑values, you lose some information about the effect sizes and their variability.\n",
        "Degrees of Freedom:\n",
        "A single test that pools the data uses all available degrees of freedom, whereas separate tests have fewer degrees of freedom each. Pooling data typically results in a more reliable estimate of the common variance.\n",
        "Meta-Analysis vs. Joint Analysis:\n",
        "Methods like Fisher’s method are designed for situations where you might not have access to the raw data (for example, if studies are published separately) or if the studies differ in design. When the experiments are identical, a joint analysis is both simpler and more statistically efficient.\n",
        "In summary, if the experiments are identical and you have access to all the raw data, it is generally more powerful to combine all the data and perform a single, unified test.\n",
        "\n",
        "Interesting. That suggests to me that, even in the independent tests in different zip codes example, i might be better off with a different method that starts with thr raw data rather than starting with t-stats or pvalues\n",
        "\n",
        "Yes, exactly. When you have access to the raw data from each zip code, a hierarchical (multilevel) model is often more powerful and efficient than analyzing each zip code separately and then combining p‑values. Here's why:\n",
        "\n",
        "Borrowing Strength: A hierarchical model pools information across zip codes. Even if each zip code provides only a weak signal individually, the model can \"borrow strength\" across the data, leading to more precise estimates of the overall effect and the variability among zip codes.\n",
        "Handling Heterogeneity: A hierarchical model can incorporate both within–zip code variability and between–zip code variability. This is particularly important if zip codes vary in sample sizes or if the treatment effect might differ slightly from one area to another.\n",
        "Direct Estimation of the Global Effect: Instead of combining summary statistics (like t‑stats or p‑values), a joint analysis of the raw data allows you to directly test whether there is an overall nonzero effect while accounting for the structure of the data.\n",
        "Flexibility: You can include covariates, random effects, or even allow for spatial correlation if that’s relevant. This flexibility can improve power and control for confounding factors.\n",
        "For example, if you have individual-level outcomes from all zip codes, you might model them as follows (in a mixed-effects framework):\n",
        "\n",
        "$$y_{ij} = \\mu + \\tau_j + \\epsilon_{ij}$$\n",
        "\n",
        "where $y_{ij}$ is the outcome for unit i in experiment j. $\\mu$ is the overall mean effect (the parameter of interest), $\\tau_j$ is the random effect for each experiment. We assume:\n",
        "\n",
        "$$\\tau_j \\stackrel{\\text{iid}}{\\sim} N(0, \\sigma^2_j)$$\n",
        "\n",
        "$$\\epsilon_{ij} \\stackrel{\\text{iid}}{\\sim} N(0, \\sigma^2)$$\n",
        "\n",
        "In Python, packages such as statsmodels (for frequentist approaches) or PyMC3/NumPyro (for Bayesian approaches) allow you to fit such models. This approach makes full use of the raw data and is typically more powerful than combining p-values from separate tests.\n",
        "\n",
        "Alternatively, if you view the zip codes as a random sample from a larger population, you might use a random effects model:\n",
        "\n",
        "\n",
        "Here, testing whether the zip codes add value means testing whether\n",
        "σ\n",
        "τ\n",
        "2\n",
        ">\n",
        "0\n",
        "σ\n",
        "τ\n",
        "2\n",
        "​\n",
        " >0. This is typically done via a likelihood ratio test, with the appropriate mixture of chi‑squares because of the boundary issue\n",
        "\n",
        " n a random effects model, the null hypothesis is that\n",
        "σ\n",
        "τ\n",
        "2\n",
        "=\n",
        "0\n",
        "σ\n",
        "τ\n",
        "2\n",
        "​\n",
        " =0. Even though the model is written with a common fixed effect\n",
        "μ\n",
        "μ, the variation among groups is captured in\n",
        "σ\n",
        "τ\n",
        "2\n",
        "σ\n",
        "τ\n",
        "2\n",
        "​\n",
        " . Testing\n",
        "H\n",
        "0\n",
        ":\n",
        "σ\n",
        "τ\n",
        "2\n",
        "=\n",
        "0\n",
        "H\n",
        "0\n",
        "​\n",
        " :σ\n",
        "τ\n",
        "2\n",
        "​\n",
        " =0 tells you whether there is any evidence that the zip codes differ.\n",
        "\n",
        " Random Effects vs. Fixed Effects\n",
        "Random Effects Model:\n",
        "In a standard random‐effects (mixed‐effects) model you write:\n",
        "\n",
        "y\n",
        "i\n",
        "j\n",
        "=\n",
        "μ\n",
        "+\n",
        "τ\n",
        "j\n",
        "+\n",
        "ε\n",
        "i\n",
        "j\n",
        ",\n",
        "y\n",
        "ij\n",
        "​\n",
        " =μ+τ\n",
        "j\n",
        "​\n",
        " +ε\n",
        "ij\n",
        "​\n",
        " ,\n",
        "where the\n",
        "τ\n",
        "j\n",
        "τ\n",
        "j\n",
        "​\n",
        " 's are assumed to be independent draws from a distribution, usually\n",
        "\n",
        "τ\n",
        "j\n",
        "∼\n",
        "N\n",
        "(\n",
        "0\n",
        ",\n",
        "σ\n",
        "τ\n",
        "2\n",
        ")\n",
        ".\n",
        "τ\n",
        "j\n",
        "​\n",
        " ∼N(0,σ\n",
        "τ\n",
        "2\n",
        "​\n",
        " ).\n",
        "Because\n",
        "E\n",
        "(\n",
        "τ\n",
        "j\n",
        ")\n",
        "=\n",
        "0\n",
        "E(τ\n",
        "j\n",
        "​\n",
        " )=0, we have\n",
        "\n",
        "E\n",
        "(\n",
        "y\n",
        "i\n",
        "j\n",
        ")\n",
        "=\n",
        "μ\n",
        ".\n",
        "E(y\n",
        "ij\n",
        "​\n",
        " )=μ.\n",
        "Under this formulation, the null hypothesis that the zip codes do not differ is equivalent to testing\n",
        "\n",
        "H\n",
        "0\n",
        ":\n",
        "σ\n",
        "τ\n",
        "2\n",
        "=\n",
        "0.\n",
        "H\n",
        "0\n",
        "​\n",
        " :σ\n",
        "τ\n",
        "2\n",
        "​\n",
        " =0.\n",
        "In other words, if\n",
        "σ\n",
        "τ\n",
        "2\n",
        "=\n",
        "0\n",
        "σ\n",
        "τ\n",
        "2\n",
        "​\n",
        " =0, then all the\n",
        "τ\n",
        "j\n",
        "τ\n",
        "j\n",
        "​\n",
        " 's are (with probability 1) 0, meaning every zip code has the same mean\n",
        "μ\n",
        "μ. This is why, in a random effects model, you test whether the variance component is zero\n",
        "\n",
        " In a standard random‐effects model, the null hypothesis is that the variance of the random intercepts is zero (i.e.\n",
        "σ\n",
        "τ\n",
        "2\n",
        "=\n",
        "0\n",
        "σ\n",
        "τ\n",
        "2\n",
        "​\n",
        " =0), which is equivalent to all the\n",
        "τ\n",
        "j\n",
        "τ\n",
        "j\n",
        "​\n",
        " 's being zero. Because this null hypothesis lies on the boundary of the parameter space (variances must be nonnegative), the likelihood ratio test (LRT) statistic doesn't follow a standard chi‐square distribution. Instead, it is asymptotically distributed as a 50:50 mixture of a point mass at zero and a chi‐square with 1 degree of freedom. This “mixture chi-square” LRT is the classical solution for testing whether it makes sense to include a random intercept (i.e. whether there is meaningful between-group variability) in these models.\n",
        "\n",
        " The model is parameterized in terms of the variance component\n",
        "σ\n",
        "τ\n",
        "2\n",
        "σ\n",
        "τ\n",
        "2\n",
        "​\n",
        " , not the individual\n",
        "τ\n",
        "j\n",
        "τ\n",
        "j\n",
        "​\n",
        " 's. Testing\n",
        "H\n",
        "0\n",
        ":\n",
        "σ\n",
        "τ\n",
        "2\n",
        "=\n",
        "0\n",
        "H\n",
        "0\n",
        "​\n",
        " :σ\n",
        "τ\n",
        "2\n",
        "​\n",
        " =0 is a single hypothesis about the distribution of the random effects. So while it might sound more intuitive to test “are all the\n",
        "τ\n",
        "j\n",
        "τ\n",
        "j\n",
        "​\n",
        "  exactly 0?”, in the context of a random effects model this is equivalent to testing whether the variance component is zero.\n",
        "\n",
        "\n",
        "  Below is an example using the likelihood‐ratio test (LRT) to compare a mixed‐effects model (with a random intercept for zip codes) to a simple fixed‐effects model (global mean only). The null hypothesis here is that the variance of the random intercepts (the\n",
        "t\n",
        "j\n",
        "t\n",
        "j\n",
        "​\n",
        " 's) is zero—i.e. that adding zip-code–specific effects does not improve the model.\n",
        "\n",
        "Because the null lies on the boundary of the parameter space (variance components must be\n",
        "≥\n",
        "0\n",
        "≥0), the usual chi‐square distribution for the LRT does not hold exactly; under the null the LRT is asymptotically distributed as a 50:50 mixture of a point mass at 0 and a chi‑square with 1 degree of freedom. (In practice many people use the mixture approximation, or they resort to a parametric bootstrap.) Here, we’ll use the mixture approximation: for an observed LRT\n",
        "x\n",
        ">\n",
        "0\n",
        "x>0, the p‑value is approximately\n",
        "\n",
        "p\n",
        "≈\n",
        "0.5\n",
        "(\n",
        "1\n",
        "−\n",
        "χ\n",
        "1\n",
        "2\n",
        "(\n",
        "x\n",
        ")\n",
        ")\n",
        ".\n",
        "p≈0.5(1−χ\n",
        "1\n",
        "2\n",
        "​\n",
        " (x)).\n",
        "If\n",
        "x\n",
        "=\n",
        "0\n",
        "x=0, we set\n",
        "p\n",
        "=\n",
        "1\n",
        "p=1.\n",
        "\n",
        "Explanation\n",
        "Data Simulation:\n",
        "We simulate data for 100 zip codes with 20 observations each. Under the null hypothesis, there is no true zip-code effect (all data come from a global distribution with mean 0).\n",
        "Full Model:\n",
        "We fit a mixed-effects model using statsmodels’ mixedlm with a random intercept for each zip code. The parameter of interest is the variance component of the random intercepts.\n",
        "Reduced Model:\n",
        "We fit a simple OLS model (global mean only), which does not allow for zip-code differences.\n",
        "Likelihood Ratio Test:\n",
        "We compute the LRT statistic:\n",
        "LRT\n",
        "=\n",
        "2\n",
        "(\n",
        "llf\n",
        "full\n",
        "−\n",
        "llf\n",
        "reduced\n",
        ")\n",
        ".\n",
        "LRT=2(llf\n",
        "full\n",
        "​\n",
        " −llf\n",
        "reduced\n",
        "​\n",
        " ).\n",
        "Because testing a variance component is on the boundary of the parameter space, we use the mixture chi‑square approximation. For\n",
        "L\n",
        "R\n",
        "T\n",
        ">\n",
        "0\n",
        "LRT>0, the p‑value is approximately:\n",
        "\n",
        "p\n",
        "≈\n",
        "0.5\n",
        "(\n",
        "1\n",
        "−\n",
        "χ\n",
        "1\n",
        "2\n",
        "(\n",
        "L\n",
        "R\n",
        "T\n",
        ")\n",
        ")\n",
        ".\n",
        "p≈0.5(1−χ\n",
        "1\n",
        "2\n",
        "​\n",
        " (LRT)).\n",
        "Interpretation:\n",
        "A significant result (small p‑value) would indicate that including zip-code–specific effects (the\n",
        "t\n",
        "j\n",
        "t\n",
        "j\n",
        "​\n",
        " 's) improves the model, i.e. that not all of them are zero.\n",
        "This approach directly tests whether the random effects (the zip-code deviations) add explanatory power beyond a single global mean."
      ],
      "metadata": {
        "id": "-0ukMYfUpw5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.formula.api as smf\n",
        "from scipy.stats import chi2\n",
        "\n",
        "# -----------------------------\n",
        "# Simulate example data:\n",
        "# -----------------------------\n",
        "np.random.seed(123)\n",
        "n_zip = 100        # number of zip codes\n",
        "n_per_zip = 20     # number of observations per zip code\n",
        "\n",
        "data = []\n",
        "# Under the null, the true model has no zip-code effect (variance component = 0)\n",
        "for i in range(n_zip):\n",
        "    for j in range(n_per_zip):\n",
        "        # All observations come from the same distribution (global mean 0)\n",
        "        y = 0 + np.random.normal(0, 2)  # global mean 0, error SD = 2\n",
        "        data.append((i, y))\n",
        "\n",
        "df = pd.DataFrame(data, columns=['zip', 'y'])\n",
        "\n",
        "# -----------------------------\n",
        "# Fit the full mixed-effects model:\n",
        "# -----------------------------\n",
        "# Model with random intercepts for each zip code.\n",
        "full_model = smf.mixedlm(\"y ~ 1\", data=df, groups=df[\"zip\"])\n",
        "full_res = full_model.fit()\n",
        "print(\"Full model (random intercepts) summary:\")\n",
        "print(full_res.summary())\n",
        "\n",
        "# -----------------------------\n",
        "# Fit the reduced model (no random effects):\n",
        "# -----------------------------\n",
        "# This is equivalent to an OLS regression with a single intercept.\n",
        "reduced_model = smf.ols(\"y ~ 1\", data=df)\n",
        "reduced_res = reduced_model.fit()\n",
        "print(\"\\nReduced model (global mean only) summary:\")\n",
        "print(reduced_res.summary())\n",
        "\n",
        "# -----------------------------\n",
        "# Likelihood Ratio Test:\n",
        "# -----------------------------\n",
        "# LRT statistic: 2*(logL_full - logL_reduced)\n",
        "LRT = 2 * (full_res.llf - reduced_res.llf)\n",
        "print(\"\\nLikelihood Ratio Test statistic:\", LRT)\n",
        "\n",
        "# Under H0, the LRT follows a 50:50 mixture: 0.5*delta(0) + 0.5*chi2(1)\n",
        "if LRT > 0:\n",
        "    p_value = 0.5 * (1 - chi2.cdf(LRT, 1))\n",
        "else:\n",
        "    p_value = 1.0\n",
        "print(\"P-value for testing that the random effects variance is zero:\", p_value)\n"
      ],
      "metadata": {
        "id": "BTIOF0ld09Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lsEeqIoGB-yx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}